{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/hasan/PycharmProjects/donut_finetuning_cpu\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.11.3 in ./.venv/lib/python3.11/site-packages (from donut-python==1.0.9) (4.38.2)\n",
      "Requirement already satisfied: timm in ./.venv/lib/python3.11/site-packages (from donut-python==1.0.9) (0.9.16)\n",
      "Requirement already satisfied: datasets[vision] in ./.venv/lib/python3.11/site-packages (from donut-python==1.0.9) (2.18.0)\n",
      "Requirement already satisfied: pytorch-lightning>=1.6.4 in ./.venv/lib/python3.11/site-packages (from donut-python==1.0.9) (2.2.1)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.11/site-packages (from donut-python==1.0.9) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in ./.venv/lib/python3.11/site-packages (from donut-python==1.0.9) (0.2.0)\n",
      "Requirement already satisfied: zss in ./.venv/lib/python3.11/site-packages (from donut-python==1.0.9) (1.2.0)\n",
      "Requirement already satisfied: sconf>=0.2.3 in ./.venv/lib/python3.11/site-packages (from donut-python==1.0.9) (0.2.5)\n",
      "Requirement already satisfied: numpy>=1.17.2 in ./.venv/lib/python3.11/site-packages (from pytorch-lightning>=1.6.4->donut-python==1.0.9) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./.venv/lib/python3.11/site-packages (from pytorch-lightning>=1.6.4->donut-python==1.0.9) (2.2.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in ./.venv/lib/python3.11/site-packages (from pytorch-lightning>=1.6.4->donut-python==1.0.9) (4.66.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./.venv/lib/python3.11/site-packages (from pytorch-lightning>=1.6.4->donut-python==1.0.9) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.4->donut-python==1.0.9) (2024.2.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in ./.venv/lib/python3.11/site-packages (from pytorch-lightning>=1.6.4->donut-python==1.0.9) (1.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from pytorch-lightning>=1.6.4->donut-python==1.0.9) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./.venv/lib/python3.11/site-packages (from pytorch-lightning>=1.6.4->donut-python==1.0.9) (4.10.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in ./.venv/lib/python3.11/site-packages (from pytorch-lightning>=1.6.4->donut-python==1.0.9) (0.10.1)\n",
      "Requirement already satisfied: ruamel.yaml in ./.venv/lib/python3.11/site-packages (from sconf>=0.2.3->donut-python==1.0.9) (0.18.6)\n",
      "Requirement already satisfied: munch in ./.venv/lib/python3.11/site-packages (from sconf>=0.2.3->donut-python==1.0.9) (4.0.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from transformers>=4.11.3->donut-python==1.0.9) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.venv/lib/python3.11/site-packages (from transformers>=4.11.3->donut-python==1.0.9) (0.21.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers>=4.11.3->donut-python==1.0.9) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from transformers>=4.11.3->donut-python==1.0.9) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.venv/lib/python3.11/site-packages (from transformers>=4.11.3->donut-python==1.0.9) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.11/site-packages (from transformers>=4.11.3->donut-python==1.0.9) (0.4.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./.venv/lib/python3.11/site-packages (from datasets[vision]->donut-python==1.0.9) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.venv/lib/python3.11/site-packages (from datasets[vision]->donut-python==1.0.9) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from datasets[vision]->donut-python==1.0.9) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from datasets[vision]->donut-python==1.0.9) (2.2.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from datasets[vision]->donut-python==1.0.9) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.11/site-packages (from datasets[vision]->donut-python==1.0.9) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from datasets[vision]->donut-python==1.0.9) (3.9.3)\n",
      "Requirement already satisfied: Pillow>=6.2.1 in ./.venv/lib/python3.11/site-packages (from datasets[vision]->donut-python==1.0.9) (10.2.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk->donut-python==1.0.9) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk->donut-python==1.0.9) (1.3.2)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.11/site-packages (from timm->donut-python==1.0.9) (0.17.1)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.11/site-packages (from zss->donut-python==1.0.9) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]->donut-python==1.0.9) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]->donut-python==1.0.9) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]->donut-python==1.0.9) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]->donut-python==1.0.9) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]->donut-python==1.0.9) (1.9.4)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=1.6.4->donut-python==1.0.9) (69.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->transformers>=4.11.3->donut-python==1.0.9) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->transformers>=4.11.3->donut-python==1.0.9) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->transformers>=4.11.3->donut-python==1.0.9) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->transformers>=4.11.3->donut-python==1.0.9) (2024.2.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning>=1.6.4->donut-python==1.0.9) (1.12)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning>=1.6.4->donut-python==1.0.9) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning>=1.6.4->donut-python==1.0.9) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->datasets[vision]->donut-python==1.0.9) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->datasets[vision]->donut-python==1.0.9) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas->datasets[vision]->donut-python==1.0.9) (2024.1)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in ./.venv/lib/python3.11/site-packages (from ruamel.yaml->sconf>=0.2.3->donut-python==1.0.9) (0.2.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->pytorch-lightning>=1.6.4->donut-python==1.0.9) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy->torch>=1.13.0->pytorch-lightning>=1.6.4->donut-python==1.0.9) (1.3.0)\n",
      "Building wheels for collected packages: donut-python\n",
      "  Building wheel for donut-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for donut-python: filename=donut_python-1.0.9-py3-none-any.whl size=21774 sha256=b6128fb1f7e15833d34be2b66593334e233b2204503cc7d924f1eea60d590849\n",
      "  Stored in directory: /private/var/folders/zg/hxpx13fs79v6f0ps79jp1ymc0000gn/T/pip-ephem-wheel-cache-s498ugpj/wheels/e8/58/5b/19dbbc44fe1e73924866bc579212a898d63bc22036af3cb671\n",
      "Successfully built donut-python\n",
      "Installing collected packages: donut-python\n",
      "  Attempting uninstall: donut-python\n",
      "    Found existing installation: donut-python 1.0.9\n",
      "    Uninstalling donut-python-1.0.9:\n",
      "      Successfully uninstalled donut-python-1.0.9\n",
      "Successfully installed donut-python-1.0.9\n",
      "Collecting tensorboardX\n",
      "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from tensorboardX) (1.26.4)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from tensorboardX) (24.0)\n",
      "Collecting protobuf>=3.20 (from tensorboardX)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Installing collected packages: protobuf, tensorboardX\n",
      "Successfully installed protobuf-4.25.3 tensorboardX-2.6.2.2\n",
      "zsh:1: unmatched '\n"
     ]
    }
   ],
   "source": [
    "!pip install .\n",
    "!pip install -U 'tensorboardX'\n",
    "!pip install -U 'tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume_from_checkpoint_path: None\n",
      "result_path: ./result\n",
      "pretrained_model_name_or_path: naver-clova-ix/donut-base\n",
      "dataset_name_or_paths: \n",
      "  - finetuning_data\n",
      "sort_json_key: False\n",
      "train_batch_sizes: \n",
      "  - 8\n",
      "val_batch_sizes: \n",
      "  - 1\n",
      "input_size: \n",
      "  - 1280\n",
      "  - 960\n",
      "max_length: 768\n",
      "align_long_axis: False\n",
      "num_nodes: 1\n",
      "seed: 2022\n",
      "lr: 3e-05\n",
      "warmup_steps: 300\n",
      "num_training_samples_per_epoch: 800\n",
      "max_epochs: -1\n",
      "max_steps: 100\n",
      "num_workers: 8\n",
      "val_check_interval: 1.0\n",
      "check_val_every_n_epoch: 3\n",
      "gradient_clip_val: 1.0\n",
      "verbose: True\n",
      "exp_name: train_cord\n",
      "exp_version: 20240310_234221\n",
      "Config is saved at result/train_cord/20240310_234221/config.yaml\n",
      "Seed set to 2022\n",
      "Some weights of DonutModel were not initialized from the model checkpoint at naver-clova-ix/donut-base and are newly initialized: ['encoder.model.layers.3.downsample.norm.bias', 'encoder.model.layers.3.downsample.norm.weight', 'encoder.model.layers.3.downsample.reduction.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DonutModel were not initialized from the model checkpoint at naver-clova-ix/donut-base and are newly initialized because the shapes did not match:\n",
      "- encoder.model.layers.1.downsample.reduction.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([256, 512]) in the model instantiated\n",
      "- encoder.model.layers.1.downsample.norm.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- encoder.model.layers.1.downsample.norm.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- encoder.model.layers.2.downsample.reduction.weight: found shape torch.Size([1024, 2048]) in the checkpoint and torch.Size([512, 1024]) in the model instantiated\n",
      "- encoder.model.layers.2.downsample.norm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "- encoder.model.layers.2.downsample.norm.bias: found shape torch.Size([2048]) in the checkpoint and torch.Size([1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Resolving data files: 100%|███████████████| 101/101 [00:00<00:00, 531524.10it/s]\n",
      "Resolving data files: 100%|█████████████████| 21/21 [00:00<00:00, 362470.72it/s]\n",
      "Resolving data files: 100%|█████████████████| 21/21 [00:00<00:00, 436041.50it/s]\n",
      "Resolving data files: 100%|███████████████| 101/101 [00:00<00:00, 202788.27it/s]\n",
      "Resolving data files: 100%|█████████████████| 21/21 [00:00<00:00, 447108.55it/s]\n",
      "Resolving data files: 100%|█████████████████| 21/21 [00:00<00:00, 182739.39it/s]\n",
      "/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:552: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /Users/hasan/PycharmProjects/donut_finetuning_cpu/result/train_cord/20240310_234221 exists and is not empty.\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | DonutModel | 201 M \n",
      "-------------------------------------\n",
      "201 M     Trainable params\n",
      "0         Non-trainable params\n",
      "201 M     Total params\n",
      "804.299   Total estimated model params size (MB)\n",
      "/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "Epoch 0:   0%|                                           | 0/13 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/train.py\", line 182, in <module>\n",
      "    train(config)\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/train.py\", line 165, in train\n",
      "    trainer.fit(model_module, data_module, ckpt_path=config.get(\"resume_from_checkpoint_path\", None))\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1033, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/amp.py\", line 77, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 75, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 385, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/torch/optim/adam.py\", line 146, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 129, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 318, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
      "    return self.lightning_module.training_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/lightning_module.py\", line 59, in training_step\n",
      "    loss = self.model(image_tensors, decoder_input_ids, decoder_labels)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/donut/model.py\", line 409, in forward\n",
      "    encoder_outputs = self.encoder(image_tensors)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/donut/model.py\", line 101, in forward\n",
      "    x = self.model.pos_drop(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hasan/PycharmProjects/donut_finetuning_cpu/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1688, in __getattr__\n",
      "    raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
      "AttributeError: 'SwinTransformer' object has no attribute 'pos_drop'\n",
      "Epoch 0:   0%|          | 0/13 [00:04<?, ?it/s]                                 \n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --config config/train_cord.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
